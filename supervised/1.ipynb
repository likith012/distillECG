{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9631c59b-2ab7-46fc-afc1-1a1f1c154153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, re\n",
    "import torch\n",
    "import numpy as np\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "SEED = 1234\n",
    "np.random.seed(SEED)\n",
    "rng = np.random.RandomState(SEED)\n",
    "\n",
    "# ARGS\n",
    "HALF_WINDOW = 3\n",
    "\n",
    "args = {}\n",
    "args['dir'] = r'C:\\Users\\likit\\Downloads\\shhs'\n",
    "\n",
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split(r'(\\d+)', text) ]\n",
    "\n",
    "DATASET_SUBJECTS = sorted(os.listdir(os.path.join(args['dir'], 'subjects_data')))\n",
    "DATASET_SUBJECTS = [os.path.join(args['dir'], 'subjects_data', f) for f in DATASET_SUBJECTS]\n",
    "TRAIN_PATH = os.path.join(args['dir'], f'train_{HALF_WINDOW}') \n",
    "TEST_PATH = os.path.join(args['dir'], f'test_{HALF_WINDOW}')\n",
    "\n",
    "dataset_subjects_data = [np.load(f) for f in DATASET_SUBJECTS]\n",
    "sub_train = rng.choice(DATASET_SUBJECTS, int(len(DATASET_SUBJECTS)*0.8), replace=False)\n",
    "sub_test = list(set(DATASET_SUBJECTS) - set(sub_train))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8bc0f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train files: 8263 \n",
      "\n",
      "Test files: 3141 \n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "import wandb, os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils.utils import *\n",
    "from utils.dataloader import distillDataset\n",
    "from helper_train import distill_train\n",
    "\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)\n",
    "\n",
    "DATASET = 'shhs'\n",
    "MODALITY = 'eeg'\n",
    "EXPERIMENT_NAME = f'supervised_{DATASET}+{MODALITY}'\n",
    "INPUT_CHANNELS = 2\n",
    "BATCH_SIZE = 256\n",
    "EPOCH_LEN = 7\n",
    "\n",
    "DATASET_PATH = r'C:\\Users\\likit\\Downloads\\shhs'\n",
    "DATASET_SUBJECTS = os.listdir(os.path.join(DATASET_PATH, 'subjects_data'))\n",
    "SAVE_PATH = './saved_weights'\n",
    "if not os.path.exists(SAVE_PATH): os.makedirs(SAVE_PATH, exist_ok=True)\n",
    "\n",
    "# wandb = wandb.init(\n",
    "#     project=\"distillECG\",\n",
    "#     name=EXPERIMENT_NAME,\n",
    "#     save_code=False,\n",
    "#     entity=\"sleep-staging\",\n",
    "# )\n",
    "# wandb.save(\"./supervised/utils/*\")\n",
    "# wandb.save(\"./supervised/models/*\")\n",
    "# wandb.save(\"./supervised/helper_train.py\")\n",
    "# wandb.save(\"./supervised/train.py\")\n",
    "\n",
    "DATASET_SUBJECTS.sort(key=natural_keys)\n",
    "DATASET_SUBJECTS = [os.path.join(DATASET_PATH, 'subjects_data', f) for f in DATASET_SUBJECTS]\n",
    "dataset_subjects_data = [np.load(f) for f in DATASET_SUBJECTS]\n",
    "\n",
    "# load files\n",
    "TRAIN_PATH = os.path.join(DATASET_PATH, f'train_{EPOCH_LEN}') \n",
    "TEST_PATH = os.path.join(DATASET_PATH, f'test_{EPOCH_LEN}')\n",
    "TRAIN_EPOCH_FILES = [os.path.join(TRAIN_PATH, f) for f in os.listdir(TRAIN_PATH)]\n",
    "TEST_EPOCH_FILES = [os.path.join(TEST_PATH, f) for f in os.listdir(TEST_PATH)]\n",
    "\n",
    "\n",
    "print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "print(f\"Train files: {len(TRAIN_EPOCH_FILES)} \\n\")\n",
    "print(f\"Test files: {len(TEST_EPOCH_FILES)} \\n\")\n",
    "print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "\n",
    "# train_dataset = distillDataset(TRAIN_EPOCH_FILES, MODALITY)\n",
    "# test_dataset = distillDataset(TEST_EPOCH_FILES, MODALITY)\n",
    "\n",
    "# train_loader = DataLoader(\n",
    "#     train_dataset,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     shuffle=True,\n",
    "#     num_workers=4,\n",
    "# )\n",
    "# test_loader = DataLoader(\n",
    "#     test_dataset,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     shuffle=False,\n",
    "#     num_workers=4,\n",
    "# )\n",
    "\n",
    "# model = distill_train(EXPERIMENT_NAME, SAVE_PATH, train_loader, test_loader, wandb, EPOCH_LEN, INPUT_CHANNELS)\n",
    "# wandb.watch([model], log=\"all\", log_freq=500)\n",
    "\n",
    "# model.fit()\n",
    "# wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a430dbe-4743-4f29-ad67-48fc8aaf4b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class d(Dataset):\n",
    "    \"\"\"Dataset for train and test\"\"\"\n",
    "\n",
    "    def __init__(self, filepath, modality):\n",
    "        super(d, self).__init__()\n",
    "        self.file_path = filepath\n",
    "        self.modality = modality\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.file_path[index]\n",
    "        data = np.load(path)\n",
    "        return data, data['y']\n",
    "\n",
    "test_dataset = d(TEST_EPOCH_FILES, MODALITY)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a72e3d2-379b-475f-8c0c-d9cd9cc9c706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8dfe892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "for i in TEST_EPOCH_FILES:\n",
    "    a = np.load(i)\n",
    "    print(type(a['eeg']))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57135745-c187-44fb-9250-6d5a028dde6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "SEED = 1234\n",
    "rng = np.random.RandomState(SEED)\n",
    "\n",
    "\n",
    "# ARGS\n",
    "HALF_WINDOW = 3 # Epoch length is HALF_WINDOW*2 + 1\n",
    "AVAILABLE_MODALITY = ['eeg', 'ecg', 'eog', 'emg', 'emog']\n",
    "\n",
    "args = {}\n",
    "args['dir'] = r\"C:\\Users\\likit\\Downloads\\shhs\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a94d7f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train subjects: 8 \n",
      "\n",
      "Test subjects: 3 \n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "DATASET_SUBJECTS = sorted(os.listdir(os.path.join(args['dir'], 'subjects_data')))\n",
    "DATASET_SUBJECTS = [os.path.join(args['dir'], 'subjects_data', f) for f in DATASET_SUBJECTS]\n",
    "TRAIN_PATH = os.path.join(args['dir'], f'train_{HALF_WINDOW}') \n",
    "TEST_PATH = os.path.join(args['dir'], f'test_{HALF_WINDOW}')\n",
    "\n",
    "dataset_subjects_data = [np.load(f) for f in DATASET_SUBJECTS]\n",
    "sub_train = rng.choice(DATASET_SUBJECTS, int(len(DATASET_SUBJECTS)*0.8), replace=False)\n",
    "sub_test = list(set(DATASET_SUBJECTS) - set(sub_train))\n",
    "train_data = [np.load(f) for f in sub_train]\n",
    "test_data = [np.load(f) for f in sub_test]\n",
    "\n",
    "print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "print(f\"Train subjects: {len(sub_train)} \\n\")\n",
    "print(f\"Test subjects: {len(sub_test)} \\n\")\n",
    "print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "\n",
    "if not os.path.exists(TRAIN_PATH): os.makedirs(TRAIN_PATH, exist_ok=True)\n",
    "if not os.path.exists(TEST_PATH): os.makedirs(TEST_PATH, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "663230b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\likit\\Downloads\\shhs\\edfs\\shhs1\\shhs1-200975.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ECG']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r'C:\\Users\\likit\\Downloads\\shhs\\edfs\\shhs1\\shhs1-200975.edf'\n",
    "\n",
    "import mne\n",
    "\n",
    "a = mne.io.read_raw_edf(path, include='ECG')\n",
    "\n",
    "a.ch_names\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b5b3f32a9b2f4e2cb14fef27893c5c45989f94303a36e8219b910dbd820a4653"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
